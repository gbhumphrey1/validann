% Generated by roxygen2 (4.1.1): do not edit by hand
% Please edit documentation in R/validann.R
\name{validann}
\alias{validann}
\alias{validann.ann}
\alias{validann.default}
\alias{validann.nnet}
\title{Validate Artificial Neural Networks.}
\usage{
validann(...)

\method{validann}{ann}(net, obs, sim, x, na.rm = TRUE, ...)

\method{validann}{nnet}(net, obs, sim, x, na.rm = TRUE, ...)

\method{validann}{default}(obs, sim, npar, na.rm = TRUE, ...)
}
\arguments{
\item{net}{an object of class `ann' (as returned by function
\code{\link{ann}}) or `nnet' (as returned using \code{\link[nnet]{nnet}}).
This is a list object comprising information about the fitted ANN model,
including values of weights, fitted target values, number of layers and
numbers of nodes in each layer, for example.}

\item{obs,sim}{vectors comprising observed (\code{obs}) and simulated
(\code{sim}) examples of a single response variable. These vectors are
used to compute model fit statistics. Optional if \code{net} is supplied
(see `Details').}

\item{x}{(optional) matrix, data frame or vector of input data used for
fitting \code{net} object. A vector is considered to comprise examples of
a single input or predictor variable. While \code{x} is optional,
sensitivity analyses useful for structural validation cannot be performed
if it is missing.}

\item{na.rm}{(optional) logical; should missing values (including NaN)
be removed from calculations?}

\item{npar}{(optional) integer; number of model parameters (ANN weights).
If not supplied, validation metrics AIC and BIC will not be
computed.}

\item{\dots}{arguments to be passed to different validann methods,
see specific formulations for details.}
}
\value{
list object of class `validann' with components dependent on
   arguments passed to \code{validann} function:

\item{predictive}{logical; if \code{TRUE}, metrics and statistics used
   for predictive validation have been computed.}
\item{replicative}{logical; if \code{TRUE}, metrics and statistics used
   for replicative validation have been computed.}
\item{structural}{logical; if \code{TRUE}, metrics and statistics used
   for structural validation have been computed.}
\item{metrics}{a data frame consisting of metrics:

   AME, PDIFF, MAE, ME, RMSE, R4MS4E, AIC, BIC, NSC, RAE, PEP, MARE,
   MdAPE, MRE, MSRE, RVE, RSqr, IoAd, CE, PI, MSLE, MSDE, IRMSE, VE,
   KGE, SSE and R.

   See Dawson et al. (2007) for definitions.}
\item{obs_stats}{a data frame consisting of summary statistics about the
   \code{obs} dataset including mean, minimum, maximum, variance,
   standard deviation, skewness and kurtosis.}
\item{sim_stats}{a data frame consisting of summary statistics about the
   \code{sim} dataset including mean, minimum, maximum, variance,
   standard deviation, skewness and kurtosis.}
\item{residuals}{a 1-column matrix of model residuals (\code{sim - obs}).}
\item{resid_stats}{a data frame consisting of summary statistics about the
   model \code{residuals} including mean, minimum, maximum, variance,
   standard deviation, skewness and kurtosis.}
\item{ri}{a data frame consisting `relative importance' values for each input
   computed using the overall connection weight (ocw), modified ocw (ocw.mod)
   and Garson's (gars) methods. Only returned if \code{net} is supplied.
   See ***refs}
\item{y_hat}{a matrix of dimension \code{c(101, ncol(x))} of model response
   values indicating the local sensitivity of the model to each input in
   \code{x}. Only returned if \code{net} and \code{x} are supplied.

   The response values returned in \code{y_hat} are calculated by carrying
   out a local sensitivity analysis, whereby the sensitivity of the model
   with respect to each input in \code{x} is considered successively.
   For each input of interest \code{x[,i]}, synthetic data are generated
   such that inputs \code{x[,-i]} are fixed to their mean values
   (as calculated from \code{x}), while input \code{x[,i]} is varied between
   its minimum and maximum value, increasing in increments of 1\% (giving
   101 synthetic values of \code{x[,i]}). These data are input into
   \code{net} and the corresponding model response values are computed and
   returned in \code{y_hat[,i]}. This process is repeated for each input
   variable in \code{x}. See Shahin et al. (2005) for further details.}
\item{rs}{a matrix of dimension \code{dim(x)} of `relative sensitivity'
   values for each input in \code{x} given the model output values
   (i.e. \code{sim}). Only returned if \code{net} and \code{x} are
   supplied and \code{net} is of class `ann'.

   The values in \code{rs} are calculated according to the partial
   derivative (P.D.) sensitivity analysis method described in Mount et al.
   (2013), which involves computing the first-order partial derivatives of
   the ANN output with respect to each input. \code{net} must be of class
   `ann' in order to access partial derivatives of the hidden layer nodes as
   returned by \code{\link{ann}}.}
}
\description{
Compute metrics and statistics for predictive, replicative
   and/or structural validation of artificial neural networks (ANNs).
}
\details{
To compute all (predictive, replicative and structural) types of
validation metrics and statistics, \code{net} must be supplied and must be
of class `ann' (as returned by \code{\link{ann}}) or `nnet' (as returned by
\code{\link[nnet]{nnet}}). However, a partial derivative (P.D.)
sensitivity analysis (useful for structural validation) will only be carried
out if \code{net} is of class `ann'.

If \code{obs} and \code{sim} data are supplied, validation metrics are
computed based on these. Otherwise, metrics and statistics are computed
based on \code{obs} and \code{sim} datasets derived from the
\code{net} object (i.e. the data used to fit \code{net} and the fitted
values). As such, both \code{obs} and \code{sim} must be
supplied if validation is to be based either on data not used for training or
on unprocessed training data (if training data were preprocessed). If either
\code{obs} or \code{sim} is specified but the other isn't, both \code{obs}
and \code{sim} will be derived from \code{net} if supplied (and a warning
will be given). Similarly, this will occur if \code{obs} and \code{sim} are
of different lengths.

If \code{net} is not supplied, both \code{obs} and
\code{sim} are required and structural validation metrics will not be
computed. This may be necessary if validating an ANN model not built using
either the \code{\link[nnet]{nnet}} or \code{\link{ann}} functions. In this case,
it is necessary to also supply \code{npar} for AIC and BIC metrics to be
returned.
}
\section{Methods (by class)}{
\itemize{
\item \code{ann}: Compute validation metrics when \code{net}
is of class `ann'.

\item \code{nnet}: Compute validation metrics when \code{net}
is of class `nnet'.

\item \code{default}: Useful when ANN model has not been developed using
either \code{\link{ann}} or \code{\link[nnet]{nnet}}. Only metrics and
statistics for predictive and replicative validation are computed.
}}
\examples{
# get validation results for 1-hidden node `ann' model fitted to ar9 data
# based on training data.
# ---
data("ar9")
samp <- sample(1:1000, 200)
y <- ar9[samp, ncol(ar9)]
x <- ar9[samp, -ncol(ar9)]
x <- x[, c(1,4,9)]

fit <- ann(x, y, size = 1, act_hid = "tanh", act_out = "linear", rang = 0.1)
results <- validann(fit, x = x)

# get validation results for above model based on a new sample of ar9 data.
# ---
samp <- sample(1:1000, 200)
y <- ar9[samp, ncol(ar9)]
x <- ar9[samp, -ncol(ar9)]
x <- x[, c(1,4,9)]

obs <- y
sim <- predict(fit, newdata = x)
results <- validann(fit, obs = obs, sim = sim, x = x)

# get validation results for `obs' and `sim' data without ANN model.
# In this example `sim' is generated using a linear model.
# validann would be called in the same way if the ANN model used to generate
# `sim' was not available or was not of class `ann' or `nnet'.
# ---
samp <- sample(1:1000, 200)
y <- ar9[samp, ncol(ar9)]
x <- ar9[samp, -ncol(ar9)]
x <- as.matrix(x[, c(1,4,9)])
lmfit <- lm.fit(x, y)
sim <- lmfit$fitted.values
obs <- y
npar <- length(lmfit$coefficients)
results <- validann(obs = obs, sim = sim, npar = npar)
}
\references{
Dawson, C.W., Abrahart, R.J., See, L.M., 2007. HydroTest: A web-based
   toolbox of evaluation metrics for the standardised assessment of
   hydrological forecasts. Environmental Modelling & Software, 22(7),
   1034-1052. \url{http://dx.doi.org/10.1016/j.envsoft.2006.06.008}.
   \url{http://co-public.lboro.ac.uk/cocwd/HydroTest/Details.html}

Shahin, M.A., Maier, H.R., Jaksa, M.B., 2005. Investigation
   into the robustness of artificial neural networks for a case study in
   civil engineering. MODSIM 2005 International Congress on Modelling and
   Simulation, December 2005,
   \url{http://www.mssanz.org.au/modsim05/papers/shahin_3.pdf}, 79-83.

Mount, N.J., Dawson, C.W., Abrahart, R.J., 2013. Legitimising
data-driven models: exemplification of a new data-driven mechanistic
modelling framework. Hydrology and Earth System Sciences 17, 2827-2843.
\url{http://dx.doi.org/10.5194/hess-17-2827-2013}.
}
\seealso{
\code{\link{ann}}, \code{\link{plot.validann}},
\code{\link{predict.ann}}
}

