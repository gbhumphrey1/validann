% Generated by roxygen2 (4.1.1): do not edit by hand
% Please edit documentation in R/ann.R
\name{ann}
\alias{ann}
\title{Fit Artificial Neural Networks.}
\usage{
ann(x, y, size, act_hid = c("sigmoid", "tanh", "linear"),
  act_out = c("linear", "sigmoid", "tanh"), Wts, rang = 0.5, objfn = sse,
  method = "BFGS", trace = TRUE, ...)
}
\arguments{
\item{x}{matrix, data frame or vector of numeric input values, with
\code{ncol(x)} equal to the number of inputs/predictors and \code{nrow(x)}
equal to the number of examples. A vector is considered to comprise examples
of a single input or predictor variable.}

\item{y}{matrix, data frame or vector of target values for examples.}

\item{size}{number of hidden layer nodes. Can be zero.}

\item{act_hid}{activation function to be used at the hidden layer.
See `Details'.}

\item{act_out}{activation function to be used at the output layer.
See `Details'.}

\item{Wts}{initial weight vector. If missing chosen at random.}

\item{rang}{initial random weights on [-rang,rang]. Default value is 0.5.}

\item{objfn}{objective function to be minimised when fitting weights.
This function may be user-defined with the first two arguments
corresponding to \code{y} (the observed target data) and \code{y_hat}
(the ANN output). Default is \code{sse} (internal function to compute sum
squared error, with error given by \code{y - y_hat}).}

\item{method}{the method to be used by \code{\link[stats]{optim}} for
minimising the objective function. May be ``Nelder-Mead'', ``BFGS'',
``CG'', ``L-BFGS-B'', ``SANN'' or ``Brent''. Can be abbreviated.
Default is ``BFGS''.}

\item{trace}{logical. Should optimization be traced? Default = TRUE.}

\item{...}{arguments to be passed to user-defined \code{objfn}.}
}
\value{
object of class `ann' with components:
\item{wts}{best set of weights found.}
\item{value}{value of fitting criterion.}
\item{fitted.values}{fitted values for the training data.}
\item{residuals}{residuals for the training data.}
\item{convergence}{1 if the maximum number of iterations was reached,
otherwise 0.}
\item{derivs}{matrix of derivatives of hidden (columns \code{1:size})
and output (final column) nodes.}
}
\description{
Fits a single hidden layer ANN model to input data \code{x} and output data
\code{y}.
}
\details{
The ``linear'' activation, or transfer, function is the
identity function where the output of a node is equal to its input
\eqn{f(x) = x}.

The ``sigmoid'' function is the standard logistic sigmoid function given by
\eqn{f(x) = \frac{1}{1+e^{-x}}}{f(x) = 1 / (1 + exp(-x))}.

The ``tanh'' function is the hyperbolic tangent function given by
\eqn{f(x) = \frac{e^{x}-e^{-x}}{e^{x}+e^{-x}}}{f(x) = (exp(x) - exp(-x)) / (exp(x) + exp(-x))}

The default configuration of activation functions is
\code{act_hid = "sigmoid"} and \code{act_out = "linear"}.

Optimization (minimization) of the objective function (\code{objfn}) is
performed by \code{\link[stats]{optim}} using the method specified.

Derivatives returned are first-order partial derivatives of the hidden and
output nodes with respect to their inputs. These may be useful for
sensitivity analyses.
}
\examples{
## fit 1-hidden node ann model with tanh activation at the hidden layer and
## linear activation at the output layer.
## Use 200 random samples from ar9 dataset.
## ---
data("ar9")
samp <- sample(1:1000, 200)
y <- ar9[samp, ncol(ar9)]
x <- ar9[samp, -ncol(ar9)]
x <- x[, c(1,4,9)]
fit <- ann(x, y, size = 1, act_hid = "tanh", act_out = "linear", rang = 0.1)

## fit 3-hidden node ann model to ar9 data with user-defined objective
## function
## ---
autocorr_sse <- function(y, y_hat, phi, sigma) {
  err <- y - y_hat
  err[-1] <- phi * err[-length(y)] + rnorm(length(y) - 1, sd = sigma)
  sum(err ^ 2)
}
fit <- ann(x, y, size = 3, act_hid = "tanh", act_out = "linear", rang = 0.1,
           objfn = autocorr_sse, phi = 0.5, sigma = 0.2)
}
\seealso{
\code{\link{predict.ann}}, \code{\link{validann}}
}

